{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP=pd.read_json(\"../data/raw/CAP/concat/casebody.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['judges', 'head_matter', 'corrections', 'opinions', 'attorneys'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAP[\"0\"][0][\"data\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Per Curiam.\\nAppellant, James Joseph Standley, Jr., by his attorney, has filed for a rule on the clerk. His attorney, Billy J. Allred, admits that the record was tendered late due to a mistake on his part.\\nWe find that such error, admittedly made by the attorney for a criminal defendant, is good cause to grant the motion. See our Per Curiam opinion dated February 5, 1979, In Re: Belated Appeals in Criminal Cases.\\nA copy of this opinion will be forwarded to the Committee on Professional Conduct.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAP[\"0\"][0][\"data\"][\"opinions\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Per Curiam.\\nAppellant, James Joseph Standley,...\n",
       "1    Per Curiam.\\nPetitioner Keith Melvin Dubray, b...\n",
       "2    Per Curiam.\\nAppellant, Avery Nathan Richardso...\n",
       "3    Per Curiam.\\nAppellant, Sammy Joe Elmore, by h...\n",
       "4    George Rose Smith, Justice.\\nThe two appellant...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_opinion(x):\n",
    "    try:\n",
    "        opinion=x[\"data\"][\"opinions\"][0][\"text\"]\n",
    "    except Exception as e:\n",
    "        opinion=\"\"\n",
    "    return opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP[\"opinions\"]=CAP[\"0\"].apply(lambda x:extract_opinion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Per Curiam.\\nAppellant, James Joseph Standley, Jr., by his attorney, has filed for a rule on the clerk. His attorney, Billy J. Allred, admits that the record was tendered late due to a mistake on his part.\\nWe find that such error, admittedly made by the attorney for a criminal defendant, is good cause to grant the motion. See our Per Curiam opinion dated February 5, 1979, In Re: Belated Appeals in Criminal Cases.\\nA copy of this opinion will be forwarded to the Committee on Professional Conduct.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAP[\"0\"][0][\"data\"][\"opinions\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Per Curiam.\\nAppellant, James Joseph Standley,...\n",
       "1         Per Curiam.\\nPetitioner Keith Melvin Dubray, b...\n",
       "2         Per Curiam.\\nAppellant, Avery Nathan Richardso...\n",
       "3         Per Curiam.\\nAppellant, Sammy Joe Elmore, by h...\n",
       "4         George Rose Smith, Justice.\\nThe two appellant...\n",
       "                                ...                        \n",
       "358701    OPINION\\nBOSSON, J.\\n{1} Charlie Taylor (Defen...\n",
       "358702    OPINION\\nWECHSLER, Judge.\\n{1} Plaintiffs-Appe...\n",
       "358703    OPINION\\nBOSSON, J.\\n{1} We consider as a matt...\n",
       "358704    OPINION\\nPICKARD, Chief Judge.\\n{1} This ease ...\n",
       "358705    OPINION\\nBUSTAMANTE, Judge.\\n{1} Angela V. Woo...\n",
       "Name: opinions, Length: 358706, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP_op=CAP[\"opinions\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per Curiam.\n",
      "Appellant, James Joseph Standley, Jr., by his attorney, has filed for a rule on the clerk. His attorney, Billy J. Allred, admits that the record was tendered late due to a mistake on his part.\n",
      "We find that such error, admittedly made by the attorney for a criminal defendant, is good cause to grant the motion. See our Per Curiam opinion dated February 5, 1979, In Re: Belated Appeals in Criminal Cases.\n",
      "A copy of this opinion will be forwarded to the Committee on Professional Conduct.\n"
     ]
    }
   ],
   "source": [
    "print(CAP_op[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/CAP/CAP.txt\",\"w\") as file:\n",
    "    file.writelines(CAP_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPPD=pd.read_csv(\"../data/raw/GPPD/patent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPPD.to_csv(\"../data/processed/GPPD/GPPD.txt\",header=None,index=None,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPPD=pd.read_csv(\"../data/raw/PL/long_descrip.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data/processed/Ensemble/Ensemble_v0.txt\",\"r\") as file:\n",
    "    Ensemble = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=int(len(Ensemble)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817248356"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran ge(40) needs more than 300G RAM\n",
    "\n",
    "Ensemble_trunks=[Ensemble[l*n:l*(n+1)] for n in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Ensemble_trunks)):\n",
    "    with open(\"../data/processed/Ensemble_splits/Ensemble_split{}.txt\".format(i),\"w\") as file:\n",
    "        file.write(Ensemble_trunks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble_trunk0=Ensemble[0:2**30-1]\n",
    "# Ensemble_trunk1=Ensemble[2**30-1:2*2**30-2]\n",
    "# Ensemble_trunk2=Ensemble[2*2**30-2:3*2**30-3]\n",
    "# Ensemble_trunk3=Ensemble[3*2**30-3:4*2**30-4]\n",
    "# Ensemble_trunk4=Ensemble[4*2**30-4:5*2**30-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=\"hello fash foi aw foaehw ifhweua of weaoufh uew hefou awh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sajf jfkjsa]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sentencizer)\n",
    "nlp.max_length=2**30\n",
    "# nlp.disable_pipes([\"tagger\", \"parser\", \"ner\"])\n",
    "for i in range(len(Ensemble_trunks)):\n",
    "    trunk=Ensemble_trunks[i]\n",
    "    doc = nlp(trunk)\n",
    "    with open(\"../data/processed/Ensemble/Ensemble_trunk{}.txt\".format(i),\"w\") as file:\n",
    "        for sent in doc.sents:\n",
    "            file.write(sent.text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import pickle\n",
    "\n",
    "def worker(procnum, return_dict,trunk):\n",
    "    \"\"\"worker function\"\"\"\n",
    "    return_dict[procnum] =[str(sent)+\"\\n\" for sent in list(nlp(trunk))]\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sentencizer)\n",
    "nlp.max_length=2**30\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "return_dict = manager.dict()\n",
    "jobs = []\n",
    "for i in range(20):\n",
    "    with open(\"../data/processed/Ensemble/Ensemble_trunk{}.txt\".format(i),\"r\") as file:\n",
    "        trunk=file.read()\n",
    "    p = multiprocessing.Process(target=worker, args=(i, return_dict,trunk))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "\n",
    "for proc in jobs:\n",
    "    proc.join()\n",
    "\n",
    "with open(\"sent_segmentation.pkl\", \"wb\") as f:\n",
    "    pickle.dump(return_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/Ensemble/Ensemble_sent_segmented.txt\",\"r\") as file:\n",
    "    sentence = file.read().splitlines()\n",
    "\n",
    "sent_df=pd.DataFrame(sentence,columns=[\"sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows containing only \\n or space\n",
    "sent_df=sent_df[sent_df['sent'].apply(lambda x:len(x.strip())>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(sent_df, test_size=0.05, random_state=0)\n",
    "\n",
    "X_val,X_test = train_test_split(X_test, test_size=0.5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39571621, 1041359, 1041358)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test),len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train.to_csv(\"../data/processed/Ensemble/legal.{}.txt\".format(\"train\"), sep='\\n', index=False,header=None)\n",
    "# X_test.to_csv(\"../data/processed/Ensemble/legal.{}.txt\".format(\"test\"), sep='\\n', index=False,header=None)\n",
    "X_val.to_csv(\"../data/processed/Ensemble/legal.{}.txt\".format(\"valid\"), sep='\\n', index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\",\"test\",\"valid\"]:\n",
    "    with open(\"../data/processed/Ensemble/legal.{}.txt\".format(split),\"w\") as file:\n",
    "            file.write(Ensemble_trunks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sentencizer)\n",
    "\n",
    "trunk=\"This is a sentence. This is another sentence.\"\n",
    "doc = nlp(trunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test.txt\",\"w\") as file:\n",
    "    for sent in doc.sents:\n",
    "        file.write(sent.text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_fix_dep_copy',\n",
       " '_recalculate_indices',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'as_doc',\n",
       " 'char_span',\n",
       " 'conjuncts',\n",
       " 'doc',\n",
       " 'end',\n",
       " 'end_char',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ents',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_extension',\n",
       " 'has_vector',\n",
       " 'kb_id',\n",
       " 'kb_id_',\n",
       " 'label',\n",
       " 'label_',\n",
       " 'lefts',\n",
       " 'lemma_',\n",
       " 'lower_',\n",
       " 'merge',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'noun_chunks',\n",
       " 'orth_',\n",
       " 'remove_extension',\n",
       " 'rights',\n",
       " 'root',\n",
       " 'sent',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'start',\n",
       " 'start_char',\n",
       " 'string',\n",
       " 'subtree',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'upper_',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(spacy.tokens.span.Span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
